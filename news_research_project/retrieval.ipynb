{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3e5400b-0507-4172-9416-ce484c50f79e",
   "metadata": {},
   "source": [
    "#### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2232b77-c286-49c5-ac68-574a7660d327",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System tools\n",
    "import os\n",
    "import pickle\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# The 'Brain' and 'Math'\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Data Loading & Vector Storage (from community & specialized packages)\n",
    "from langchain_community.document_loaders import UnstructuredURLLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Building chains with raw LCEL primitives\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8461e2bb-7bb5-4169-94e6-ac4bc8151a85",
   "metadata": {},
   "source": [
    "#### Setup Models (Initialize the AI and Keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f7c21693-c733-40c0-8279-d1405867aced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load API keys\n",
    "os.chdir(r\"C:\\Users\\shedd\\Desktop\\Personal Projects\\gen_ai\")\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize Llama 3 on Groq and local embeddings\n",
    "# Note: The underscore import 'langchain_groq', not 'langchain.chat_models'\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-versatile\", temperature=0.5)\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f91da618-0e43-42a7-8a57-da31401ca184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Groq API Key Detected: Yes\n",
      "Embedding Model Ready: all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "source": [
    "print(f\"Groq API Key Detected: {'Yes' if os.environ.get('GROQ_API_KEY') else 'No'}\")\n",
    "print(f\"Embedding Model Ready: {embeddings.model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d1bc9-6f81-4eba-a02d-4418ac5ce062",
   "metadata": {},
   "source": [
    "#### Load & Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf03f8cd-277b-4054-9502-6918c3708a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "urls = [\n",
    "    \"https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html\",\n",
    "    \"https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\"\n",
    "]\n",
    "\n",
    "loader = UnstructuredURLLoader(urls=urls)\n",
    "data = loader.load()\n",
    "\n",
    "# Using the specialized 'langchain_text_splitters' package\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "docs = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29851f45-ed41-4cb3-80d6-65b5b1a6b2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Articles Loaded: 2\n",
      "Total Chunks Created: 17\n",
      "\n",
      "--- First Chunk Preview ---\n",
      "English\n",
      "\n",
      "Hindi\n",
      "\n",
      "Gujarati\n",
      "\n",
      "Specials\n",
      "\n",
      "Hello, Login\n",
      "\n",
      "Hello, Login\n",
      "\n",
      "Log-inor Sign-Up\n",
      "\n",
      "My Account\n",
      "\n",
      "My Profile\n",
      "\n",
      "My Portfolio\n",
      "\n",
      "My Watchlist\n",
      "\n",
      "My Alerts\n",
      "\n",
      "My Messages\n",
      "\n",
      "Price Alerts\n",
      "\n",
      "My Profile\n",
      "\n",
      "My PRO\n",
      "\n",
      "My Portfolio\n",
      "\n",
      "My Watchlist\n",
      "\n",
      "My Alerts\n",
      "\n",
      "My Messages\n",
      "\n",
      "Price Alerts\n",
      "\n",
      "Logout\n",
      "\n",
      "Loans up to â‚¹50 LAKHS\n",
      "\n",
      "Fixed Deposits\n",
      "\n",
      "Credit CardsLifetime Free\n",
      "\n",
      "Credit Score\n",
      "\n",
      "Chat with Us\n",
      "\n",
      "Download App\n",
      "\n",
      "Follow us on:\n",
      "\n",
      "Network 18\n",
      "\n",
      "Go Ad-Free\n",
      "\n",
      "My Alerts\n",
      "\n",
      ">->MC_ENG_DESKTOP/MC_ENG_NEWS/MC_ENG_MARKETS_AS/MC_ENG_ROS_NWS_MKTS_AS_ATF_7\n",
      "\n",
      "--- Source Metadata ---\n",
      "{'source': 'https://www.moneycontrol.com/news/business/markets/wall-street-rises-as-tesla-soars-on-ai-optimism-11351111.html'}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Articles Loaded: {len(data)}\")\n",
    "print(f\"Total Chunks Created: {len(docs)}\\n\")\n",
    "\n",
    "# Preview the first chunk to check for clean text\n",
    "print(\"--- First Chunk Preview ---\")\n",
    "print(docs[0].page_content[:500])  # Show first 500 characters\n",
    "print(\"\\n--- Source Metadata ---\")\n",
    "print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ae6e18-b627-4683-9664-e5ff34997e32",
   "metadata": {},
   "source": [
    "#### Build Vector Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e699354-d7f0-4924-8b67-eb926c1a7986",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all those text chunks into vector numbers and store them in FAISS\n",
    "# This is where the \"learning\" actually happens\n",
    "vector_index = FAISS.from_documents(docs, embeddings)\n",
    "\n",
    "# We'll save this as a simple pickle file right here in the project folder\n",
    "file_path = \"vector_index.pkl\"\n",
    "\n",
    "with open(file_path, \"wb\") as f:\n",
    "    pickle.dump(vector_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb90cb96-e078-4126-967d-a017edf5945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Index saved to: vector_index.pkl\n",
      "\n",
      "--- Raw Search Results ---\n",
      "Result 1: The company also said it has also introduced the twin-cylinder technology on its Tiago and Tigor models.\n",
      "\n",
      "The Tiago iCNG is priced between Rs 6.55 lak...\n",
      "Source: https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\n",
      "\n",
      "Result 2: Trending Topics\n",
      "\n",
      "Sensex Live\n",
      "\n",
      "Union Budget 2026\n",
      "\n",
      "IPO This Week\n",
      "\n",
      "Kuku IPO\n",
      "\n",
      "Gold Rate Today\n",
      "\n",
      "Tata Motors launches Punch iCNG, price starts at Rs 7.1 lak...\n",
      "Source: https://www.moneycontrol.com/news/business/tata-motors-launches-punch-icng-price-starts-at-rs-7-1-lakh-11098751.html\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check if the file was actually created\n",
    "if os.path.exists(file_path):\n",
    "    print(f\"Success! Index saved to: {file_path}\")\n",
    "    \n",
    "    # Quick sanity check: Ask the raw index a question without the AI model\n",
    "    # We want to make sure it can actually find relevant chunks\n",
    "    test_query = \"price of Tiago iCNG\"\n",
    "    results = vector_index.similarity_search(test_query, k=2)\n",
    "    \n",
    "    print(\"\\n--- Raw Search Results ---\")\n",
    "    for i, res in enumerate(results):\n",
    "        print(f\"Result {i+1}: {res.page_content[:150]}...\") # Show first 150 chars\n",
    "        print(f\"Source: {res.metadata['source']}\\n\")\n",
    "else:\n",
    "    print(\"Error: The file wasn't saved. Check your permissions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5651835-29f4-4167-b2e5-07d169162953",
   "metadata": {},
   "source": [
    "#### The LCEL Pipeline (Ask Questions and Get Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b938946f-3126-4e62-8079-9828fc6d4862",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"Brain\" back into memory\n",
    "# We open the pickle file we saved earlier. This is crucial because in a real app,\n",
    "# you don't want to rebuild the index every time a user asks a question.\n",
    "with open(\"vector_index.pkl\", \"rb\") as f:\n",
    "    loaded_index = pickle.load(f)\n",
    "\n",
    "# create the \"Search Engine\"\n",
    "# We convert our static index into a 'retriever' that can actively search.\n",
    "# I'm setting 'k=2' here, which tells it: \"Don't read the whole internet, \n",
    "# just bring me the top 2 most relevant snippets.\" This saves time and tokens.\n",
    "retriever = loaded_index.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# Give the AI its instructions (The Prompt)\n",
    "# This is where we control the personality and accuracy. \n",
    "# By saying \"based ONLY on the following context,\" we prevent it from making things up (hallucinating).\n",
    "template = \"\"\"\n",
    "You are a helpful financial assistant. \n",
    "Answer the question based ONLY on the following context.\n",
    "If you don't know, just say \"I don't know\".\n",
    "\n",
    "Context: \n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "# A helper to glue the text together\n",
    "# The retriever returns a list of separate documents, but the LLM just wants one big string of text.\n",
    "# This function joins them all together with newlines.\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Connect the dots (The Chain)\n",
    "# This uses LCEL (LangChain Expression Language) to build a pipeline.\n",
    "# Think of the '|' symbol as a pipe passing data to the next step:\n",
    "#   1. Find relevant data (retriever) & Keep the user's question\n",
    "#   2. Feed both into the Prompt\n",
    "#   3. Send Prompt to the LLM (Groq)\n",
    "#   4. Clean up the output so it's just a string\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "26af7984-3821-459d-b16f-0664f8594fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: what is the price of Tiago iCNG?\n",
      "Answer: The Tiago iCNG is priced between Rs 6.55 lakh and Rs 8.1 lakh.\n"
     ]
    }
   ],
   "source": [
    "# run the whole pipeline with a real question\n",
    "question = \"what is the price of Tiago iCNG?\"\n",
    "final_answer = rag_chain.invoke(question)\n",
    "\n",
    "print(f\"Question: {question}\")\n",
    "print(f\"Answer: {final_answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d7e10-55d9-4200-96af-934f870ad578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (dev_env)",
   "language": "python",
   "name": "dev_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
